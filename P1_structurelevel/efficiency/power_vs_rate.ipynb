{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef5405d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torch\n",
    "from kan import KAN\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    \"CUDA initialization: Unexpected error from cudaGetDeviceCount\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d743c59",
   "metadata": {},
   "source": [
    "##### Loading the inference model and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e96dba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Using device: cpu \n",
      "\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n",
      "[mlp] Mean batch inference time: 0.0001 seconds\n",
      "[mlp] Inference time: 0.3882 seconds\n",
      "[logic_mlp] Mean batch inference time: 0.0001 seconds\n",
      "[logic_mlp] Inference time: 0.3307 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyang44/miniconda3/envs/LTN/lib/python3.11/site-packages/kan/MultKAN.py:813: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1724898583682/work/aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
      "/home/zyang44/miniconda3/envs/LTN/lib/python3.11/site-packages/kan/MultKAN.py:823: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1724898583682/work/aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  input_range = torch.std(preacts, dim=0) + 0.1\n",
      "/home/zyang44/miniconda3/envs/LTN/lib/python3.11/site-packages/kan/MultKAN.py:824: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1724898583682/work/aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
      "/home/zyang44/miniconda3/envs/LTN/lib/python3.11/site-packages/kan/MultKAN.py:825: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1724898583682/work/aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[logiKNet] Mean batch inference time: 0.0170 seconds\n",
      "[logiKNet] Inference time: 67.9692 seconds\n",
      "[hierarchical_logiKNet] Mean batch inference time: 0.0169 seconds\n",
      "[hierarchical_logiKNet] Inference time: 67.8724 seconds\n"
     ]
    }
   ],
   "source": [
    "################################setup######################################\n",
    "def load_csv_data(input_folder: str,\n",
    "                  train_fname: str,\n",
    "                  test_fname: str):\n",
    "    \"\"\"\n",
    "    Reads train & test CSVs from disk.\n",
    "    \n",
    "    Returns:\n",
    "      train_df, test_df (both pandas.DataFrame)\n",
    "    \"\"\"\n",
    "    train_path = os.path.join(input_folder, train_fname)\n",
    "    test_path  = os.path.join(input_folder, test_fname)\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df  = pd.read_csv(test_path)\n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "def extract_features_labels(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into numpy feature array X and label vector y.\n",
    "    \n",
    "    The last column is the label.\n",
    "    \"\"\"\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:,  -1].values\n",
    "    return X, y\n",
    "\n",
    "# this is a standard PyTorch DataLoader to load the dataset for the training and testing of the model\n",
    "class DataLoader(object):\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 batch_size=1,\n",
    "                 shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.data.shape[0] / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        n = self.data.shape[0]\n",
    "        idxlist = list(range(n))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxlist)\n",
    "\n",
    "        for _, start_idx in enumerate(range(0, n, self.batch_size)):\n",
    "            end_idx = min(start_idx + self.batch_size, n)\n",
    "            data = self.data[idxlist[start_idx:end_idx]]\n",
    "            labels = self.labels[idxlist[start_idx:end_idx]]\n",
    "            ############################################################\n",
    "            # Check if any class is missing in the batch\n",
    "            # present_classes = np.unique(labels.cpu().numpy())\n",
    "            # all_classes = np.arange(len(label_mapping))  # Adjust based on number of classes\n",
    "            # missing_classes = set(all_classes) - set(present_classes)\n",
    "            #\n",
    "            # if missing_classes:\n",
    "            #     print(f\"Batch {start_idx // self.batch_size} is missing classes {missing_classes}\")\n",
    "            ############################################################\n",
    "            yield data, labels\n",
    "\n",
    "\n",
    "class LogitsToPredicate(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model has inside a logits model, that is a model which compute logits for the classes given an input example x.\n",
    "    The idea of this model is to keep logits and probabilities separated. The logits model returns the logits for an example,\n",
    "    while this model returns the probabilities given the logits model.\n",
    "\n",
    "    In particular, it takes as input an example x and a class label l. It applies the logits model to x to get the logits.\n",
    "    Then, it applies a softmax function to get the probabilities per classes. Finally, it returns only the probability related\n",
    "    to the given class l.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logits_model):\n",
    "        super(LogitsToPredicate, self).__init__()\n",
    "        self.logits_model = logits_model\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, l, training=False):\n",
    "        logits = self.logits_model(x, training=training)\n",
    "        probs = self.softmax(logits)\n",
    "        out = torch.sum(probs * l, dim=1)  # 计算并返回与给定类标签l对应的概率值\n",
    "        return out\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This model returns the logits for the classes given an input example. It does not compute the softmax, so the output\n",
    "    are not normalized.\n",
    "    This is done to separate the accuracy computation from the satisfaction level computation. Go through the example\n",
    "    to understand it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.elu = torch.nn.ELU()\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "                                                  for i in range(1, len(layer_sizes))])\n",
    "\n",
    "    def forward(self, x, training=False):\n",
    "        \"\"\"\n",
    "        Method which defines the forward phase of the neural network for our multi class classification task.\n",
    "        In particular, it returns the logits for the classes given an input example.\n",
    "\n",
    "        :param x: the features of the example\n",
    "        :param training: whether the network is in training mode (dropout applied) or validation mode (dropout not applied)\n",
    "        :return: logits for example x\n",
    "        \"\"\"\n",
    "        for layer in self.linear_layers[:-1]:\n",
    "            x = self.elu(layer(x))\n",
    "            if training:\n",
    "                x = self.dropout(x)\n",
    "        logits = self.linear_layers[-1](x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class MultiKANModel(torch.nn.Module):\n",
    "    def __init__(self, kan):\n",
    "        \"\"\"\n",
    "        Wrap an already built MultKAN instance.\n",
    "        Args:\n",
    "            kan: a MultKAN model (which has attributes such as act_fun, symbolic_fun, node_bias, node_scale,\n",
    "                 subnode_bias, subnode_scale, depth, width, mult_homo, mult_arity, input_id, symbolic_enabled, etc.)\n",
    "        \"\"\"\n",
    "        super(MultiKANModel, self).__init__()\n",
    "        self.kan = kan\n",
    "\n",
    "    def forward(self, x, training=False, singularity_avoiding=False, y_th=10.):\n",
    "        # Select input features according to input_id\n",
    "        x = x[:, self.kan.input_id.long()]\n",
    "        # Loop through each layer\n",
    "        for l in range(self.kan.depth):\n",
    "            # Get outputs from the numerical branch (KANLayer) of current layer\n",
    "            x_numerical, preacts, postacts_numerical, postspline = self.kan.act_fun[l](x)\n",
    "            # Get output from the symbolic branch if enabled\n",
    "            if self.kan.symbolic_enabled:\n",
    "                x_symbolic, postacts_symbolic = self.kan.symbolic_fun[l](x, singularity_avoiding=singularity_avoiding, y_th=y_th)\n",
    "            else:\n",
    "                x_symbolic = 0.\n",
    "            # Sum the numerical and symbolic outputs\n",
    "            x = x_numerical + x_symbolic\n",
    "\n",
    "            # Subnode affine transformation\n",
    "            x = self.kan.subnode_scale[l][None, :] * x + self.kan.subnode_bias[l][None, :]\n",
    "\n",
    "            # Process multiplication nodes\n",
    "            dim_sum = self.kan.width[l+1][0]\n",
    "            dim_mult = self.kan.width[l+1][1]\n",
    "            if dim_mult > 0:\n",
    "                if self.kan.mult_homo:\n",
    "                    for i in range(self.kan.mult_arity-1):\n",
    "                        if i == 0:\n",
    "                            x_mult = x[:, dim_sum::self.kan.mult_arity] * x[:, dim_sum+1::self.kan.mult_arity]\n",
    "                        else:\n",
    "                            x_mult = x_mult * x[:, dim_sum+i+1::self.kan.mult_arity]\n",
    "                else:\n",
    "                    for j in range(dim_mult):\n",
    "                        acml_id = dim_sum + int(np.sum(self.kan.mult_arity[l+1][:j]))\n",
    "                        for i in range(self.kan.mult_arity[l+1][j]-1):\n",
    "                            if i == 0:\n",
    "                                x_mult_j = x[:, [acml_id]] * x[:, [acml_id+1]]\n",
    "                            else:\n",
    "                                x_mult_j = x_mult_j * x[:, [acml_id+i+1]]\n",
    "                        if j == 0:\n",
    "                            x_mult = x_mult_j\n",
    "                        else:\n",
    "                            x_mult = torch.cat([x_mult, x_mult_j], dim=1)\n",
    "                # Concatenate sum and mult parts\n",
    "                x = torch.cat([x[:, :dim_sum], x_mult], dim=1)\n",
    "\n",
    "            # Node affine transformation\n",
    "            x = self.kan.node_scale[l][None, :] * x + self.kan.node_bias[l][None, :]\n",
    "\n",
    "        # Final x corresponds to the logits output of the whole model\n",
    "        return x\n",
    "\n",
    "\n",
    "def save_model(model, model_save_folder, model_name):\n",
    "    \"\"\"\n",
    "    Save the model to disk.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), os.path.join(model_save_folder, model_name))\n",
    "\n",
    "    print(f\"Model saved to {os.path.join(model_save_folder, model_name)}\")\n",
    "\n",
    "\n",
    "def load_model_state(infer_model, model_save_folder, model_name):\n",
    "    \"\"\"\n",
    "    Load the model from disk.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(\n",
    "        os.path.join(model_save_folder, model_name),\n",
    "        map_location=device,\n",
    "        weights_only=True     # <-- only load tensor weights, no pickle objects\n",
    "    )\n",
    "    infer_model.load_state_dict(checkpoint)\n",
    "    infer_model.eval()\n",
    "    return infer_model\n",
    "\n",
    "\n",
    "def compute_accuracy(loader, model):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for data, labels in loader:\n",
    "        logits = model(data)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        total_correct += (preds == labels).sum()\n",
    "        total_samples += labels.numel()\n",
    "    return total_correct.float() / total_samples\n",
    "\n",
    "\n",
    "def compute_sat_levels(loader, P):\n",
    "\tsat_level  = 0\n",
    "\tfor data, labels in loader:\n",
    "\t\tx = ltn.Variable(\"x\", data)\n",
    "\t\tx_MQTT_DDoS_Connect_Flood = ltn.Variable(\"x_MQTT_DDoS_Connect_Flood\", data[labels == 0])\n",
    "\t\tx_MQTT_DDoS_Publish_Flood = ltn.Variable(\"x_MQTT_DDoS_Publish_Flood\", data[labels == 1])\n",
    "\t\tx_MQTT_DoS_Connect_Flood = ltn.Variable(\"x_MQTT_DoS_Connect_Flood\", data[labels == 2])\n",
    "\t\tx_MQTT_DoS_Publish_Flood = ltn.Variable(\"x_MQTT_DoS_Publish_Flood\", data[labels == 3])\n",
    "\t\tx_MQTT_Malformed_Data = ltn.Variable(\"x_MQTT_Malformed_Data\", data[labels == 4])\n",
    "\t\tx_Benign = ltn.Variable(\"x_Benign\", data[labels == 5])\n",
    "\n",
    "\t\tsat_level = SatAgg(\n",
    "\t\t\tForall(x_MQTT_DDoS_Connect_Flood, P(x_MQTT_DDoS_Connect_Flood, l_MQTT_DDoS_Connect_Flood)),\n",
    "\t\t\tForall(x_MQTT_DDoS_Publish_Flood, P(x_MQTT_DDoS_Publish_Flood, l_MQTT_DDoS_Publish_Flood)),\n",
    "\t\t\tForall(x_MQTT_DoS_Connect_Flood, P(x_MQTT_DoS_Connect_Flood, l_MQTT_DoS_Connect_Flood)),\n",
    "\t\t\tForall(x_MQTT_DoS_Publish_Flood, P(x_MQTT_DoS_Publish_Flood, l_MQTT_DoS_Publish_Flood)),\n",
    "\t\t\tForall(x_MQTT_Malformed_Data, P(x_MQTT_Malformed_Data, l_MQTT_Malformed_Data)),\n",
    "\t\t\tForall(x_Benign, P(x_Benign, l_Benign))\n",
    "\t\t)\n",
    "\treturn sat_level\n",
    "\n",
    "\n",
    "##############################Load data######################################\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")  # Use CPU for this example\n",
    "print(f\"\\n Using device: {device} \\n\")\n",
    "\n",
    "# Load data\n",
    "input_folder = '/home/zyang44/Github/baseline_cicIOT/P1_structurelevel/efficiency/input_files'\n",
    "train_fname = 'logiKNet_train_35945.csv'\n",
    "test_fname = 'logiKNet_test_3994.csv'\n",
    "\n",
    "train_df, test_df = load_csv_data(input_folder, train_fname, test_fname)\n",
    "# Extract features and labels   \n",
    "X_train, y_train = extract_features_labels(train_df)\n",
    "X_test, y_test = extract_features_labels(test_df)\n",
    "\n",
    "dataset_numeric = {\n",
    "    'train_input': torch.tensor(X_train, dtype=torch.float32, device=device),\n",
    "    'train_label': torch.tensor(y_train, dtype=torch.long, device=device),\n",
    "    'test_input': torch.tensor(X_test, dtype=torch.float32, device=device),\n",
    "    'test_label': torch.tensor(y_test, dtype=torch.long, device=device)\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset_numeric['train_input'],\n",
    "    dataset_numeric['train_label'], \n",
    "    batch_size=len(X_train), \n",
    "    shuffle=True\n",
    "    )\n",
    "test_loader = DataLoader(\n",
    "    dataset_numeric['test_input'],\n",
    "    dataset_numeric['test_label'],\n",
    "    # batch_size=32,\n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "###############################load model and testing########################################\n",
    "model_state_folder = '/home/zyang44/Github/baseline_cicIOT/P1_structurelevel/efficiency/model_weights'\n",
    "\n",
    "# load all four models\n",
    "mlp_infer = MLP(layer_sizes=(18, 10, 6)).to(device)\n",
    "mlp_infer = load_model_state(mlp_infer, model_state_folder, 'mlp.pt')\n",
    "\n",
    "logicmlp_infer = MLP(layer_sizes=(18, 10, 6)).to(device)\n",
    "logicmlp_infer = load_model_state(logicmlp_infer, model_state_folder, 'logic_mlp.pt')\n",
    "\n",
    "logiKNet_infer = KAN(width=[18, 10, 6], grid=5, k=3, seed=42, device=device)\n",
    "logiKNet_infer = load_model_state(logiKNet_infer, model_state_folder, 'logiKNet.pt')\n",
    "\n",
    "hierarchical_logiKNet_infer = KAN(width=[18, 10, 6], grid=5, k=3, seed=42, device=device)\n",
    "hierarchical_logiKNet_infer = load_model_state(hierarchical_logiKNet_infer, model_state_folder, 'hierarchical_logiKNet.pt')\n",
    "\n",
    "model_list = {\n",
    "    'mlp': mlp_infer,\n",
    "    'logic_mlp': logicmlp_infer,\n",
    "    'logiKNet': logiKNet_infer,\n",
    "    'hierarchical_logiKNet': hierarchical_logiKNet_infer\n",
    "}\n",
    "\n",
    "# test the models \n",
    "def test_model(model, loader, model_name=\"\"):\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    model.eval()\n",
    "    batch_times = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in loader:\n",
    "            batch_start = time.perf_counter()\n",
    "            logits = model(data)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            batch_end = time.perf_counter()\n",
    "            batch_times.append(batch_end - batch_start)\n",
    "\n",
    "    if batch_times:\n",
    "        mean_time = sum(batch_times) / len(batch_times)\n",
    "        print(f\"[{model_name}] Mean batch inference time: {mean_time:.4f} seconds\")\n",
    "    else:\n",
    "        print(f\"[{model_name}] No batches to measure.\") \n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"[{model_name}] Inference time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "for model_name, model in model_list.items():\n",
    "    test_model(model, test_loader, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732432a1",
   "metadata": {},
   "source": [
    "##### Persistent Processing Power vs Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149f863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LTN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
