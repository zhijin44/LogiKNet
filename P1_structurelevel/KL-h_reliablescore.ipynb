{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Any NaN in test_X_scaled: False\n",
      "Any Inf in test_X_scaled: False\n",
      "Unique train_y values: [0 1] [0 1 2 3 4 5]\n",
      "Unique test_y values: [0 1] [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import LogitsToPredicate, MLP, MultiKANModel, DataLoader, DataLoaderMulti\n",
    "from kan import KAN\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "X_columns = [\n",
    "    'Header_Length', 'Protocol Type', 'Duration', 'Rate', 'Srate', \n",
    "    # 'Drate',\n",
    "    # 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number',\n",
    "    # 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "    # 'syn_count', 'fin_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'Telnet',\n",
    "    # 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IGMP', \n",
    "    'IPv','LLC', \n",
    "    'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number',\n",
    "    'Magnitue', 'Radius', 'Covariance',\n",
    "    # 'Variance', 'Weight'\n",
    "]\n",
    "\n",
    "Y_columns = ['label_L1', 'label_L2']\n",
    "\n",
    "label_L1_mapping = {\"MQTT\": 0, \"Benign\": 1} \n",
    "label_L2_mapping = {\"MQTT-DDoS-Connect_Flood\": 0, \"MQTT-DDoS-Publish_Flood\": 1, \n",
    "                    \"MQTT-DoS-Connect_Flood\": 2, \"MQTT-DoS-Publish_Flood\": 3,\n",
    "                    \"MQTT-Malformed_Data\": 4, \"Benign\": 5} \n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/home/zyang44/Github/baseline_cicIOT/CIC_IoMT/19classes/filtered_train_l_2_6.csv')\n",
    "df['label_L1'] = df['label_L1'].map(label_L1_mapping)\n",
    "df['label_L2'] = df['label_L2'].map(label_L2_mapping)\n",
    "\n",
    "# Shuffle the dataframe before splitting into training and test sets\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "# 90% as training set and 10% as test set\n",
    "train_size = int(len(df) * 0.9)\n",
    "train_df, test_df = df.iloc[:train_size, :], df.iloc[train_size:, :]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_df[X_columns])\n",
    "test_X_scaled = scaler.transform(test_df[X_columns])\n",
    "print(\"Any NaN in test_X_scaled:\", np.isnan(test_X_scaled).any())\n",
    "print(\"Any Inf in test_X_scaled:\", np.isinf(test_X_scaled).any())\n",
    "\n",
    "train_y = train_df[Y_columns].values\n",
    "test_y = test_df[Y_columns].values\n",
    "print(\"Unique train_y values:\", np.unique(train_y[:, 0]), np.unique(train_y[:, 1]))\n",
    "print(\"Unique test_y values:\", np.unique(test_y[:, 0]), np.unique(test_y[:, 1]))\n",
    "\n",
    "train_loader_multi = DataLoaderMulti(\n",
    "    data=torch.tensor(train_X_scaled, dtype=torch.float32),\n",
    "    labels=torch.tensor(train_y, dtype=torch.long),\n",
    "    batch_size=len(train_df))\n",
    "test_loader_multi = DataLoaderMulti(\n",
    "    data=torch.tensor(test_X_scaled, dtype=torch.float32),\n",
    "    labels=torch.tensor(test_y, dtype=torch.long),\n",
    "    batch_size=len(test_df))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    data=torch.tensor(train_X_scaled, dtype=torch.float32),\n",
    "    labels=torch.tensor(train_y[:, 1], dtype=torch.long),\n",
    "    batch_size=len(train_df))\n",
    "test_loader = DataLoader(\n",
    "    data=torch.tensor(test_X_scaled, dtype=torch.float32),\n",
    "    labels=torch.tensor(test_y[:, 1], dtype=torch.long),\n",
    "    batch_size=len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "import ltn.fuzzy_ops\n",
    "\n",
    "# define the connectives, quantifiers, and the SatAgg\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())   # And = ltn.Connective(custom_fuzzy_ops.AndProd())\n",
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()\n",
    "\n",
    "# define ltn constants\n",
    "l_MQTT_DDoS_Connect_Flood = ltn.Constant(torch.tensor([1, 0, 0, 0, 0, 0]))\n",
    "l_MQTT_DDoS_Publish_Flood = ltn.Constant(torch.tensor([0, 1, 0, 0, 0, 0]))\n",
    "l_MQTT_DoS_Connect_Flood = ltn.Constant(torch.tensor([0, 0, 1, 0, 0, 0]))\n",
    "l_MQTT_DoS_Publish_Flood = ltn.Constant(torch.tensor([0, 0, 0, 1, 0, 0]))\n",
    "l_MQTT_Malformed_Data = ltn.Constant(torch.tensor([0, 0, 0, 0, 1, 0]))\n",
    "l_Benign = ltn.Constant(torch.tensor([0, 0, 0, 0, 0, 1]))\n",
    "\n",
    "l_MQTT = ltn.Constant(torch.tensor([1,0]))\n",
    "l_Benign = ltn.Constant(torch.tensor([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(loader, model):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for data, labels in loader:\n",
    "        logits = model(data)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        total_correct += (preds == labels).sum()\n",
    "        total_samples += labels.numel()\n",
    "    return total_correct.float() / total_samples\n",
    "\n",
    "def compute_accuracy_multi(loader, model):\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for data, labels in loader:\n",
    "        logits = model(data)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        total_correct += (preds == labels).sum()\n",
    "        total_samples += labels.numel()\n",
    "    return total_correct.float() / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sat_levels(loader, P):\n",
    "\tsat_level  = 0\n",
    "\tfor data, labels in loader:\n",
    "\t\tx = ltn.Variable(\"x\", data)\n",
    "\t\tx_MQTT_DDoS_Connect_Flood = ltn.Variable(\"x_MQTT_DDoS_Connect_Flood\", data[labels == 0])\n",
    "\t\tx_MQTT_DDoS_Publish_Flood = ltn.Variable(\"x_MQTT_DDoS_Publish_Flood\", data[labels == 1])\n",
    "\t\tx_MQTT_DoS_Connect_Flood = ltn.Variable(\"x_MQTT_DoS_Connect_Flood\", data[labels == 2])\n",
    "\t\tx_MQTT_DoS_Publish_Flood = ltn.Variable(\"x_MQTT_DoS_Publish_Flood\", data[labels == 3])\n",
    "\t\tx_MQTT_Malformed_Data = ltn.Variable(\"x_MQTT_Malformed_Data\", data[labels == 4])\n",
    "\t\tx_Benign = ltn.Variable(\"x_Benign\", data[labels == 5])\n",
    "\n",
    "\t\tx_MQTT = ltn.Variable(\"x_MQTT\", data[labels < 5])\n",
    "\t\t\n",
    "\t\tsat_level = SatAgg(\n",
    "\t\t\tForall(x_MQTT_DDoS_Connect_Flood, P(x_MQTT_DDoS_Connect_Flood, l_MQTT_DDoS_Connect_Flood)),\n",
    "\t\t\tForall(x_MQTT_DDoS_Publish_Flood, P(x_MQTT_DDoS_Publish_Flood, l_MQTT_DDoS_Publish_Flood)),\n",
    "\t\t\tForall(x_MQTT_DoS_Connect_Flood, P(x_MQTT_DoS_Connect_Flood, l_MQTT_DoS_Connect_Flood)),\n",
    "\t\t\tForall(x_MQTT_DoS_Publish_Flood, P(x_MQTT_DoS_Publish_Flood, l_MQTT_DoS_Publish_Flood)),\n",
    "\t\t\tForall(x_MQTT_Malformed_Data, P(x_MQTT_Malformed_Data, l_MQTT_Malformed_Data)),\n",
    "\t\t\tForall(x_Benign, P(x_Benign, l_Benign)),\n",
    "\t\t\t# hierarchical constraints\n",
    "\t\t\tForall(x_MQTT, Not(P(x_MQTT, l_Benign)))\n",
    "\t\t)\n",
    "\treturn sat_level\n",
    "\n",
    "kan_h = KAN(width=[18, 10, 6], grid=5, k=3, seed=42, device=device)\n",
    "P_kan = ltn.Predicate(LogitsToPredicate(MultiKANModel(kan_h)))\n",
    "\n",
    "kan_h_L1 = KAN(width=[18, 6, 2], grid=5, k=3, seed=42, device=device)\n",
    "P_kan_L1 = ltn.Predicate(LogitsToPredicate(MultiKANModel(kan_h_L1)))\n",
    "\n",
    "params = list(P_kan.parameters()) + list(P_kan_L1.parameters())\n",
    "optimizer_2kan = torch.optim.Adam(params, lr=0.001)\n",
    "optimizer_kan = torch.optim.Adam(P_kan.parameters(), lr=0.001)\n",
    "\n",
    "sat_tune = []\n",
    "acc_tune = []\n",
    "for epoch in range(1):\n",
    "    # Train the KAN\n",
    "\toptimizer_kan.zero_grad()\n",
    "\tsat_kan = compute_sat_levels(train_loader, P_kan)\n",
    "\tloss = 1. - sat_kan\n",
    "\tloss.backward()\n",
    "\toptimizer_kan.step()\n",
    "\ttrain_loss_kan = loss.item()\n",
    "\n",
    "\tsat_tune.append(sat_kan.item())\n",
    "\n",
    "\t# Test the KAN\n",
    "\tacc_kan = compute_accuracy(test_loader, kan_h)\n",
    "\tacc_tune.append(acc_kan.item())\n",
    "\t# if epoch % 10 == 0:\n",
    "\ttest_sat_kan = compute_sat_levels(test_loader, P_kan)\n",
    "\tprint(f\"Epoch {epoch} | KAN (loss/acc/sat): {train_loss_kan:.3f}/{acc_kan:.3f}/{sat_kan:.3f}({test_sat_kan:.3f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LTN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
