{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Data prepared.\n",
      "Train set: (torch.Size([33048, 20]), torch.Size([33048, 4]))\n",
      "Test set: (torch.Size([3672, 20]), torch.Size([3672, 4]))\n"
     ]
    }
   ],
   "source": [
    "from kan import KAN\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "X_columns = [\n",
    "    'Header_Length', 'Protocol Type', 'Duration', 'Rate', 'Srate', \n",
    "    # 'Drate',\n",
    "    # 'fin_flag_number', 'syn_flag_number', 'rst_flag_number', 'psh_flag_number',\n",
    "    # 'ack_flag_number', 'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "    # 'syn_count', 'fin_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'Telnet',\n",
    "    # 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IGMP', \n",
    "    'IPv','LLC', \n",
    "    'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number',\n",
    "    'Magnitue', 'Radius', 'Covariance',\n",
    "    'Variance', 'Weight'\n",
    "]\n",
    "\n",
    "Y_columns = ['label_L1']\n",
    "\n",
    "label_L1_mapping = {\"MQTT\": 0, \"Benign\": 1, \"Recon\": 2, \"ARP_Spoofing\": 3}\n",
    "label_L2_mapping = {\"MQTT-DDoS-Connect_Flood\": 4, \"MQTT-DDoS-Publish_Flood\": 5, \n",
    "                    \"MQTT-DoS-Connect_Flood\": 6, \"MQTT-DoS-Publish_Flood\": 7,\n",
    "                    \"MQTT-Malformed_Data\": 8, \"benign\": 9, \n",
    "                    \"Recon-OS_Scan\": 10, \"Recon-Port_Scan\": 11,\n",
    "                    \"arp_spoofing\": 12}\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/home/zyang44/Github/baseline_cicIOT/CIC_IoMT/19classes/filtered_train_s_4_11.csv')\n",
    "\n",
    "df['label_L1'] = df['label_L1'].map(label_L1_mapping)\n",
    "df['label_L2'] = df['label_L2'].map(label_L1_mapping)\n",
    "\n",
    "# 90% as training set and 10% left as test set\n",
    "train_size = int(len(df) * 0.9)\n",
    "train_df, test_df = df.iloc[:train_size, :], df.iloc[train_size:, :]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_df[X_columns])\n",
    "test_X_scaled = scaler.transform(test_df[X_columns])\n",
    "train_y = train_df[Y_columns].values.ravel()\n",
    "test_y = test_df[Y_columns].values.ravel()\n",
    "\n",
    "# take Y_columns as the label, and transfering to one-hot coded\n",
    "dataset = {\n",
    "    'train_input': torch.tensor(train_X_scaled, dtype=torch.float32, device=device),\n",
    "    'train_label': F.one_hot(torch.tensor(train_y, dtype=torch.long, device=device), num_classes=4),\n",
    "    'test_input': torch.tensor(test_X_scaled, dtype=torch.float32, device=device),\n",
    "    'test_label': F.one_hot(torch.tensor(test_y, dtype=torch.long, device=device), num_classes=4)\n",
    "}\n",
    "print(\"Data prepared.\",\n",
    "      f\"Train set: {dataset['train_input'].shape, dataset['train_label'].shape}\",\n",
    "      f\"Test set: {dataset['test_input'].shape, dataset['test_label'].shape}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 2.57e-01 | test_loss: 4.93e-01 | reg: 1.20e+03 | : 100%|â–ˆ| 100/100 [00:03<00:00, 32.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "KAN output:\n",
      "Train logits torch.Size([33048, 4])\n",
      "Test logits torch.Size([3672, 4])\n"
     ]
    }
   ],
   "source": [
    "# create a KAN\n",
    "kan = KAN(width=[20, 10, 4], grid=5, k=3, seed=42, device=device)\n",
    "\n",
    "results = kan.fit(dataset, opt=\"Adam\", steps=100)\n",
    "\n",
    "train_logits = kan(dataset['train_input'])\n",
    "test_logits = kan(dataset['test_input'])\n",
    "print(\"KAN output:\",\n",
    "      f\"Train logits {train_logits.shape}\",\n",
    "      f\"Test logits {test_logits.shape}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ltn\n",
    "import ltn.fuzzy_ops\n",
    "from utils import MLP, LogitsToPredicate, DataLoaderMulti\n",
    "\n",
    "# define the connectives, quantifiers, and the SatAgg\n",
    "Not = ltn.Connective(ltn.fuzzy_ops.NotStandard())\n",
    "And = ltn.Connective(ltn.fuzzy_ops.AndProd())   # And = ltn.Connective(custom_fuzzy_ops.AndProd())\n",
    "Or = ltn.Connective(ltn.fuzzy_ops.OrProbSum())\n",
    "Forall = ltn.Quantifier(ltn.fuzzy_ops.AggregPMeanError(p=2), quantifier=\"f\")\n",
    "Exists = ltn.Quantifier(ltn.fuzzy_ops.AggregPMean(p=2), quantifier=\"e\")\n",
    "Implies = ltn.Connective(ltn.fuzzy_ops.ImpliesReichenbach())\n",
    "SatAgg = ltn.fuzzy_ops.SatAgg()\n",
    "\n",
    "# define ltn constants\n",
    "l_MQTT = ltn.Constant(torch.tensor([1, 0, 0, 0, ]))\n",
    "l_Benign = ltn.Constant(torch.tensor([0, 1, 0, 0]))\n",
    "l_Recon = ltn.Constant(torch.tensor([0, 0, 1, 0]))\n",
    "l_ARP_Spoofing = ltn.Constant(torch.tensor([0, 0, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2294,  0.0687,  0.0212, -0.3057], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(layer_sizes=(20, 32, 4)).to(device)\n",
    "\n",
    "P_mlp = ltn.Predicate(LogitsToPredicate(mlp))\n",
    "x = ltn.Variable(\"x\", dataset['test_input'])\n",
    "\n",
    "print(mlp(dataset['test_input'])[1])\n",
    "\n",
    "# P_kan = ltn.Predicate(LogitsToPredicate(kan))\n",
    "\n",
    "# sat_agg = SatAgg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LTN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
